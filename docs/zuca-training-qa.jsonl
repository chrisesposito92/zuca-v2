{"instruction": "What is ZUCA?", "response": "ZUCA (Zuora Use Case Architect) is an AI-powered solution architect tool that generates complete Zuora Billing and Zuora Revenue configurations from natural language use case descriptions.\n\nZUCA takes a customer's business scenario (like 'annual SaaS subscription with monthly billing and usage overage') and automatically produces:\n- Subscription specifications with rate plans and charges\n- POB (Performance Obligation) template mappings for revenue recognition\n- Contracts/Orders tables for Zuora Revenue\n- Complete billing schedules\n- Revenue recognition waterfalls\n- Assumptions and open questions summary\n\nIt's designed for Zuora solution architects, implementation consultants, and pre-sales engineers who need to quickly design Zuora configurations for customer use cases.", "category": "definitional", "topic": "ZUCA overview"}
{"instruction": "What problem does ZUCA solve?", "response": "ZUCA solves several key challenges in Zuora solution design:\n\n**1. Speed:** Manually designing a complete Zuora Billing + Revenue configuration can take hours. ZUCA generates a complete solution in minutes.\n\n**2. Consistency:** Different architects may design the same use case differently. ZUCA applies consistent patterns based on 38+ reference implementations (Golden Use Cases).\n\n**3. Revenue Recognition Complexity:** Mapping charges to the correct POB templates requires deep Zuora Revenue knowledge. ZUCA automates this with built-in POB template rules.\n\n**4. Documentation:** ZUCA outputs complete tables (Contracts/Orders, Billings, Revenue Waterfall) that can be used for customer presentations or implementation handoffs.\n\n**5. Knowledge Capture:** Through its self-learning system, ZUCA captures and applies organizational knowledge about Zuora best practices.\n\n**6. Training:** ZUCA serves as a learning tool for new team members to understand Zuora configuration patterns.", "category": "conceptual", "topic": "ZUCA value proposition"}
{"instruction": "How does the ZUCA pipeline work?", "response": "ZUCA uses an optimized 6-step pipeline (v2 architecture):\n\n**Step 1: Analyze Contract (Combined)**\n- Extracts contract intelligence: dates, terms, billing parameters\n- Detects Zuora Billing and Revenue capabilities\n- Single LLM call for efficiency\n\n**Step 2: Match Golden Use Cases (Pure Code)**\n- Compares detected capabilities against 38+ reference implementations\n- Uses Jaccard similarity scoring\n- No LLM call - pure algorithmic matching\n\n**Step 3: Design Subscription (Combined)**\n- Generates subscription specification with rate plans and charges\n- Assigns POB templates for each charge\n- Single LLM call produces both outputs\n\n**Step 4: Build Contracts/Orders + Billings (Parallel)**\n- Runs both steps simultaneously for speed\n- Contracts/Orders: Creates ZR contracts table with allocated prices\n- Billings: Generates complete billing schedule\n\n**Step 5: Build Revenue Recognition Waterfall**\n- Calculates monthly revenue recognition based on POB templates\n- Applies SSP allocations, ratable spreading, event-driven recognition\n\n**Step 6: Summarize**\n- Consolidates all assumptions made during processing\n- Lists open questions that need customer clarification\n\nThe pipeline supports multi-turn conversations for follow-up questions and solution refinements.", "category": "conceptual", "topic": "ZUCA pipeline architecture"}
{"instruction": "What is the ZUCA input format?", "response": "ZUCA accepts structured input describing a customer use case:\n\n```typescript\ninterface ZucaInput {\n  customer_name: string;           // Customer/company name\n  contract_start_date: string;     // MM/DD/YYYY format\n  terms_months: number;            // Contract term in months\n  transaction_currency: 'USD' | 'EUR' | 'CAD';\n  billing_period: 'Monthly' | 'Quarterly' | 'Semi-Annually' | 'Annually';\n  is_allocations: boolean;         // Perform revenue allocations\n  allocation_method?: 'Use List Price' | 'Use Sell Price' | 'Custom Formula' | 'N/A';\n  allocation_custom_formula?: string;\n  rev_rec_notes?: string;          // Additional rev rec notes\n  use_case_description: string;    // Main use case description (natural language)\n}\n```\n\n**Example:**\n```json\n{\n  \"customer_name\": \"Acme Corp\",\n  \"contract_start_date\": \"01/01/2025\",\n  \"terms_months\": 12,\n  \"transaction_currency\": \"USD\",\n  \"billing_period\": \"Monthly\",\n  \"is_allocations\": true,\n  \"allocation_method\": \"Use List Price\",\n  \"use_case_description\": \"Annual SaaS platform subscription at $1,200/year with $500 one-time implementation fee. Usage overage at $0.10 per API call over 10,000 monthly.\"\n}\n```\n\nThe `use_case_description` is the key field where natural language describes the business scenario.", "category": "definitional", "topic": "ZUCA input schema"}
{"instruction": "What outputs does ZUCA generate?", "response": "ZUCA generates a comprehensive solution package with 9 main components:\n\n**1. Contract Intel**\n- Extracted dates: service start/end, go-live, booking\n- Term months, billing period, billing timing (in advance/arrears)\n- Trigger event for billing\n\n**2. Detected Capabilities**\n- Zuora Billing capabilities (e.g., 'Recurring Charges', 'Usage Overage')\n- Zuora Revenue capabilities (e.g., 'SSP Allocation', 'Ratable Recognition')\n- Hints about the configuration approach\n\n**3. Matched Golden Use Cases**\n- Similar reference implementations with similarity scores\n- Capability intersections and gaps\n\n**4. Subscription Specification**\n- Rate plans with names and descriptions\n- Charges with type, model, pricing, effective dates\n- Billing parameters for each charge\n\n**5. POB Mapping**\n- Each charge mapped to a POB template identifier\n- Recognition windows (start/end dates)\n- Ratable method and rationale\n\n**6. Contracts/Orders Table**\n- Line items with sell prices and allocated prices\n- SSP values and allocation percentages\n- Zuora Revenue contract structure\n\n**7. Billings Table**\n- Complete billing schedule by period\n- Invoice dates, charge periods, amounts\n- Running totals\n\n**8. Revenue Recognition Waterfall**\n- Monthly revenue by charge/POB\n- Period-by-period recognition amounts\n- Total recognized vs. deferred\n\n**9. Summary**\n- Key assumptions made during analysis\n- Open questions requiring customer clarification", "category": "definitional", "topic": "ZUCA outputs"}
{"instruction": "What are Golden Use Cases in ZUCA?", "response": "Golden Use Cases are 38+ curated reference implementations that represent common Zuora Billing and Revenue configuration patterns.\n\n**Purpose:**\n- Provide proven templates for common scenarios\n- Enable similarity matching to find relevant patterns\n- Serve as training data for the LLM to understand Zuora configurations\n\n**Structure of a Golden Use Case:**\n- Title and description\n- Billing capabilities (e.g., 'Recurring - Monthly', 'Usage - Overage')\n- Revenue capabilities (e.g., 'OT Ratable - Daily', 'PIT - Completion Event')\n- Sample subscription with rate plans and charges\n- POB template assignments\n\n**How Matching Works:**\n1. ZUCA detects capabilities from the user's use case description\n2. Compares against each Golden Use Case using Jaccard similarity\n3. Scores based on capability overlap (billing + revenue)\n4. Returns top matches to inform the solution design\n\n**Example Golden Use Cases:**\n- 'SaaS Annual Subscription with Monthly Billing'\n- 'Prepaid Usage Credits with Drawdown'\n- 'Professional Services with Milestone Billing'\n- 'Platform + Usage Overage Bundle'\n\nGolden Use Cases help ZUCA produce consistent, best-practice configurations.", "category": "conceptual", "topic": "Golden Use Cases"}
{"instruction": "How does ZUCA handle POB template mapping?", "response": "ZUCA automatically maps each charge to the appropriate POB (Performance Obligation) template for revenue recognition.\n\n**The Mapping Process:**\n\n1. **Analyze Charge Characteristics:**\n   - Charge type (Recurring, OneTime, Usage)\n   - Billing pattern (upfront, in arrears, event-driven)\n   - Service delivery pattern\n\n2. **Consider Revenue Recognition Rules:**\n   - Over Time vs Point In Time satisfaction\n   - Release event (Booking, Billing, Custom Event)\n   - Ratable method (Daily, Partial Monthly, Immediate)\n\n3. **Select POB Template:**\n   - Maps to one of 25 configured POB templates\n   - Templates follow naming convention: [Release]-[Satisfaction]-[Variant]\n   - Example: BK-OT-RATABLE = Booking, Over Time, Ratable\n\n**Output Structure (pob_mapping):**\n```json\n{\n  \"charge_pob_map\": [\n    {\n      \"charge_name\": \"Platform Subscription\",\n      \"pob_identifier\": \"BK-OT-RATABLE\",\n      \"recognition_window\": {\n        \"start_date\": \"2025-01-01\",\n        \"end_date\": \"2025-12-31\"\n      },\n      \"ratable_method\": \"Ratable\",\n      \"rationale\": \"SaaS subscription recognized ratably over service period\"\n    }\n  ]\n}\n```\n\n**Valid POB Templates:**\n- BK-* (Booking Release): BK-OT-RATABLE, BK-PIT-STARTDATE, etc.\n- BL-* (Billing Release): BL-OT-INVRATABLE, BL-PIT-CONSUMP-PAYGO, etc.\n- EVT-* (Event Release): EVT-PIT-COMPLETION, EVT-PIT-CONSUMP-USAGE, etc.", "category": "conceptual", "topic": "POB template mapping"}
{"instruction": "What is the ZUCA self-learning system?", "response": "ZUCA includes an automated self-learning system that improves pipeline quality over time through a feedback loop.\n\n**Architecture Components:**\n\n1. **Test Suites** (`data/test-suites/*.yaml`)\n   - Curated test cases with inputs and expected behaviors\n   - Can be generated from real company research\n\n2. **Evaluation Criteria** (`data/evaluation-criteria/*.yaml`)\n   - Behavioral rules for each pipeline step\n   - Defines what 'good' output looks like\n\n3. **LLM Judge**\n   - Evaluates pipeline outputs against criteria\n   - Identifies failures and patterns\n   - Supports ensemble judging with multiple models\n\n4. **Corrections Store**\n   - Captures what went wrong and how to fix it\n   - Stored as contrastive examples (wrong vs. right)\n   - Injected into prompts to prevent repeat mistakes\n\n5. **Prompt Evolution**\n   - Analyzes failure patterns\n   - Suggests permanent prompt improvements\n   - Supports approve/apply workflow\n\n6. **Training Data Export**\n   - Exports passing outputs as fine-tuning examples\n   - JSONL format compatible with HuggingFace/OpenAI\n\n**Key Commands:**\n```bash\nnpm run cli evaluate --suite golden-scenarios --corrections\nnpm run cli self-improve --auto-suggest\nnpm run cli corrections list\nnpm run cli prompts analyze\nnpm run cli training export data/training.jsonl\n```\n\nThe system enables ZUCA to learn from its mistakes and continuously improve.", "category": "conceptual", "topic": "Self-learning system"}
{"instruction": "How do I run ZUCA from the command line?", "response": "ZUCA provides a comprehensive CLI for all operations:\n\n**Analyze a Use Case:**\n```bash\n# From JSON file\nnpm run cli analyze examples/sample-use-case.json\n\n# With output file\nnpm run cli analyze examples/sample-use-case.json -o results.json\n\n# With specific model\nnpm run cli analyze examples/sample-use-case.json -m gemini-3-pro-preview\n\n# Interactive mode\nnpm run cli interactive\n\n# Quick capability detection\nnpm run cli quick \"Annual SaaS subscription with monthly billing\"\n```\n\n**Generate Use Cases:**\n```bash\n# Research a company and generate use cases\nnpm run cli -- generate \"Salesforce\" -w \"https://www.salesforce.com\" -c 3\n\n# With output file\nnpm run cli -- generate \"Datadog\" -w \"https://www.datadoghq.com\" -c 2 -o generated-uc/datadog.json\n```\n\n**Self-Learning:**\n```bash\n# Run evaluation\nnpm run cli evaluate --suite golden-scenarios\n\n# Generate corrections\nnpm run cli evaluate --corrections\n\n# Self-improvement loop\nnpm run cli self-improve --auto-suggest\n\n# Manage corrections\nnpm run cli corrections list\nnpm run cli corrections summary\n```\n\n**Available Models:**\n- gpt-5.2 (default)\n- gemini-3-pro-preview\n- gemini-3-flash-preview", "category": "procedural", "topic": "CLI usage"}
{"instruction": "What is the ZUCA web interface?", "response": "ZUCA includes a Next.js web application that provides a user-friendly interface for all functionality.\n\n**Key Features:**\n\n1. **Analyze Page**\n   - Form-based input for use case details\n   - Real-time streaming of pipeline progress\n   - Interactive results display\n\n2. **Results View**\n   - Subscription specification cards\n   - POB mapping visualization\n   - Collapsible tables for Contracts/Orders, Billings, Waterfall\n   - Multi-turn conversation for follow-ups\n\n3. **Revenue Snapshot**\n   - Connects to live Zuora tenants\n   - Previews Revenue ingestion from Billing data\n   - Excel export capability\n   - Rev Rec chart toggle and table filtering\n\n4. **Session Management**\n   - Persistent sessions stored in Postgres\n   - Resume previous analyses\n   - View session history\n\n**Running the Web App:**\n```bash\n# Development mode\nnpm run dev:web\n\n# Access at http://localhost:3000\n```\n\n**Tech Stack:**\n- Next.js 16 with App Router\n- HeroUI component library\n- Tailwind CSS with custom theme\n- Vercel Postgres for sessions\n- React Query for data fetching\n\nThe web interface provides the same capabilities as the CLI with a more accessible UI.", "category": "definitional", "topic": "Web interface"}
{"instruction": "What LLM models does ZUCA support?", "response": "ZUCA supports multiple LLM providers and models:\n\n**OpenAI Models:**\n- **gpt-5.2** (default) - Latest GPT model with strong reasoning\n  - Configurable reasoning effort: low, medium, high\n  - Uses Responses API with structured outputs\n\n**Google Gemini Models:**\n- **gemini-3-pro-preview** - High capability, more expensive\n- **gemini-3-flash-preview** - Faster, more cost-effective\n\n**Configuration:**\n```env\n# .env file\nOPENAI_API_KEY=your-key\nGEMINI_API_KEY=your-key\nLLM_MODEL=gpt-5.2\nOPENAI_REASONING_EFFORT=medium\n```\n\n**Model Selection:**\n- All steps in a single run use the same model (no mixing)\n- Model can be overridden per CLI command with `-m` flag\n- Web app allows model selection in the UI\n\n**Tool Support by Provider:**\n\n| Tool | OpenAI | Gemini |\n|------|--------|--------|\n| Web Search | `web_search` | `google_search` |\n| Code Execution | `code_interpreter` | `code_execution` |\n| URL Context | N/A | `url_context` |\n| Zuora MCP | Supported | Supported |\n\n**Recommendations:**\n- Use gpt-5.2 for highest quality output\n- Use gemini-3-flash-preview for faster iteration during development\n- Use gemini-3-pro-preview as a balance of speed and quality", "category": "definitional", "topic": "LLM model support"}
{"instruction": "How does ZUCA integrate with Zuora APIs via MCP?", "response": "ZUCA can optionally integrate with Zuora APIs through the Model Context Protocol (MCP) for real-time data access.\n\n**Configuration:**\n```env\nZUORA_MCP_SERVER_URL=http://localhost:8080/mcp\n```\n\n**Available MCP Tools:**\n\n1. **ask_zuora**\n   - Queries Zuora product knowledge base\n   - Provides guidance on Zuora features and best practices\n\n2. **query_objects**\n   - Queries Zuora objects (Accounts, Subscriptions, etc.)\n   - Supports filtering, pagination, expansion\n\n3. **zuora_codegen**\n   - Generates Zuora API code snippets\n   - Supports multiple languages (Python, Java, Node.js)\n\n**How It Works:**\n\n1. ZUCA provides MCP tools to the LLM during pipeline execution\n2. LLM decides when to use tools (e.g., to look up product catalog)\n3. Tool calls are executed against the MCP server\n4. Results are incorporated into the response\n\n**Use Cases:**\n- Look up existing products in a tenant\n- Validate charge models against catalog\n- Retrieve rate plan structures for reference\n\n**Transport:**\n- OpenAI: Streamable HTTP or SSE\n- Gemini: Direct JSON-RPC HTTP calls\n\nMCP integration is optional - ZUCA works fully offline with built-in knowledge.", "category": "conceptual", "topic": "MCP integration"}
{"instruction": "What is the ZUCA RAG system?", "response": "ZUCA includes a Retrieval-Augmented Generation (RAG) system that injects relevant Zuora documentation into pipeline steps.\n\n**Dual Backend Architecture:**\n\n| Backend | Use Case | Detection |\n|---------|----------|----------|\n| Postgres (pgvector) | Production, web app | `POSTGRES_URL` present |\n| Local JSON | CLI dev, offline | No `POSTGRES_URL` |\n\n**How RAG Works:**\n\n1. **Document Corpus:**\n   - Scraped from docs.zuora.com\n   - Chunked into semantic segments\n   - Embedded using text embeddings\n\n2. **Query Process:**\n   - Pipeline step sends a query (e.g., 'prepaid usage drawdown')\n   - RAG retrieves most relevant document chunks\n   - Chunks are injected into the prompt before LLM call\n\n3. **RAG-Enhanced Steps:**\n   - `expert-assistant` - Answers Zuora questions\n   - `analyze-contract` - Enriched with billing/revenue concepts\n   - `design-subscription` - Enriched with charge model and POB info\n\n**Setup Commands:**\n```bash\n# Build local index (one-time, ~30 min)\nnpm run rag:build\n\n# Migrate to Postgres for production\nnpm run rag:migrate\n\n# Test search\nnpm run rag:test \"contract modification\"\n```\n\n**Benefits:**\n- Keeps LLM grounded in Zuora documentation\n- Handles edge cases and recent feature changes\n- Reduces hallucination about Zuora capabilities", "category": "conceptual", "topic": "RAG system"}
{"instruction": "How do I create test suites for ZUCA evaluation?", "response": "ZUCA test suites are YAML files that define test cases for the self-learning system.\n\n**Test Suite Structure:**\n```yaml\nname: golden-scenarios\nversion: \"1.0\"\ndescription: Core test cases for pipeline validation\n\ntest_cases:\n  - id: tc-001\n    name: \"Basic SaaS Annual Subscription\"\n    description: \"Simple recurring subscription with monthly billing\"\n    input:\n      customer_name: \"Test Corp\"\n      contract_start_date: \"01/01/2025\"\n      terms_months: 12\n      transaction_currency: \"USD\"\n      billing_period: \"Monthly\"\n      is_allocations: true\n      allocation_method: \"Use List Price\"\n      use_case_description: \"Annual SaaS subscription at $1,200/year\"\n    focus_steps:\n      - design_subscription\n      - billings\n    tags:\n      - basic\n      - recurring\n```\n\n**Key Fields:**\n- `input`: Complete ZucaInput for the test case\n- `focus_steps`: Which pipeline steps to evaluate\n- `tags`: For filtering and organization\n\n**Creating from Real Companies:**\n```bash\n# Generate use cases from company website\nnpm run cli -- generate \"Salesforce\" -w \"https://www.salesforce.com\" -c 3 -o /tmp/uc/salesforce.json\n\n# Convert to test suite\nnpm run uc:to-suite -- /tmp/uc/ data/test-suites/real-world-scenarios.yaml\n```\n\n**Running Tests:**\n```bash\nnpm run cli evaluate --suite golden-scenarios\nnpm run cli evaluate --suite real-world-scenarios --step billings\n```\n\nTest suites are stored in `data/test-suites/`.", "category": "procedural", "topic": "Test suite creation"}
{"instruction": "What evaluation criteria does ZUCA use?", "response": "ZUCA evaluation criteria are YAML files that define behavioral rules for judging pipeline outputs.\n\n**Criteria Structure:**\n```yaml\nname: billings-criteria\nversion: \"1.0\"\nstep: billings\ndescription: Rules for billing schedule generation\n\ncriteria:\n  - id: BL-001\n    name: invoice-date-accuracy\n    description: Invoice dates must align with billing period\n    severity: critical\n    patterns: [invoice, date, billing period]\n    check:\n      type: behavioral\n      rule: |\n        Invoice dates must fall on the billing cycle date.\n        Monthly billing = invoice on the same day each month.\n        Annual billing = invoice on contract anniversary.\n    examples:\n      passing:\n        - scenario: \"Monthly billing starting Jan 15\"\n          expected: \"Invoices on Jan 15, Feb 15, Mar 15...\"\n      failing:\n        - scenario: \"Monthly billing starting Jan 15\"\n          incorrect: \"Invoices on Jan 1, Feb 1, Mar 1...\"\n          why: \"Ignores the contract start date\"\n```\n\n**Key Fields:**\n- `severity`: critical, high, medium, low\n- `patterns`: Keywords to detect when this rule applies\n- `check.rule`: Natural language description of correct behavior\n- `examples`: Passing and failing scenarios\n\n**Available Criteria Files:**\n- `design_subscription.yaml` - Subscription spec rules\n- `billings.yaml` - Billing schedule rules\n- `contracts_orders.yaml` - Revenue contracts rules\n- `revrec_waterfall.yaml` - Revenue recognition rules\n\n**How Judging Works:**\n1. LLM judge receives output + applicable criteria\n2. Evaluates output against each rule\n3. Returns pass/fail with explanations\n4. Failures generate corrections for learning\n\nCriteria are stored in `data/evaluation-criteria/`.", "category": "procedural", "topic": "Evaluation criteria"}
{"instruction": "How does ZUCA handle promotional pricing and price ramps?", "response": "ZUCA handles promotional pricing (step-up pricing, ramps, introductory offers) by creating separate charges for each pricing period.\n\n**The Problem:**\nA contract with '3 months at $15, then 9 months at $20' should NOT be represented as a single charge with an averaged price.\n\n**ZUCA's Approach:**\n\n1. **Detect Price Changes:**\n   - Identifies different pricing periods in the use case description\n   - Recognizes patterns like 'first X months', 'promotional', 'then'\n\n2. **Create Separate Charges:**\n   ```json\n   {\n     \"charges\": [\n       {\n         \"name\": \"Platform - Promo Period\",\n         \"sellPrice\": 15.00,\n         \"effectiveStart\": \"2025-01-01\",\n         \"effectiveEnd\": \"2025-03-31\"\n       },\n       {\n         \"name\": \"Platform - Standard Period\",\n         \"sellPrice\": 20.00,\n         \"effectiveStart\": \"2025-04-01\",\n         \"effectiveEnd\": \"2025-12-31\"\n       }\n     ]\n   }\n   ```\n\n3. **Map Each to POB:**\n   - Both charges get appropriate POB templates\n   - Recognition windows match effective periods\n   - Revenue recognized at actual contracted rates\n\n**Evaluation Criteria (DS-001):**\nThis is a critical rule - the system explicitly checks that step-up pricing creates separate charge segments rather than collapsing into averaged pricing.\n\n**Why This Matters:**\n- Accurate revenue recognition per period\n- Correct billing amounts\n- Proper SSP allocation if applicable", "category": "conceptual", "topic": "Promotional pricing handling"}
{"instruction": "What charge types and models does ZUCA support?", "response": "ZUCA supports all Zuora Billing charge types and models:\n\n**Charge Types:**\n- **Recurring**: Subscription fees billed periodically (monthly, quarterly, annually)\n- **OneTime**: One-time fees (setup, implementation, activation)\n- **Usage**: Consumption-based charges (API calls, storage, transactions)\n\n**Charge Models:**\n- **FlatFee**: Fixed amount regardless of quantity\n- **PerUnit**: Price per unit × quantity\n- **Volume**: Quantity determines price tier, all units at that tier's price\n- **Tiered**: Progressive pricing across quantity tiers\n- **Overage**: Charges for usage beyond included amount\n\n**Charge Functions:**\n- **None**: Standard charge\n- **Prepayment**: Upfront payment for future usage\n- **Drawdown**: Deducts from prepaid balance\n- **Commit**: Minimum usage commitment\n\n**Example Subscription Spec:**\n```json\n{\n  \"charges\": [\n    {\n      \"name\": \"Platform Access\",\n      \"chargeType\": \"Recurring\",\n      \"chargeModel\": \"FlatFee\",\n      \"sellPrice\": 1000.00,\n      \"billingPeriod\": \"Month\"\n    },\n    {\n      \"name\": \"Implementation\",\n      \"chargeType\": \"OneTime\",\n      \"chargeModel\": \"FlatFee\",\n      \"sellPrice\": 5000.00\n    },\n    {\n      \"name\": \"API Overage\",\n      \"chargeType\": \"Usage\",\n      \"chargeModel\": \"PerUnit\",\n      \"sellPrice\": 0.001,\n      \"uom\": \"API Calls\",\n      \"includedUnits\": 100000\n    }\n  ]\n}\n```\n\nZUCA automatically selects the appropriate combination based on the use case description.", "category": "definitional", "topic": "Charge types and models"}
{"instruction": "How does ZUCA generate the Revenue Recognition Waterfall?", "response": "The Revenue Recognition Waterfall is ZUCA's output showing monthly revenue recognition based on POB template rules.\n\n**Generation Process:**\n\n1. **Gather Inputs:**\n   - Subscription charges with sell prices\n   - POB mappings with templates and recognition windows\n   - Allocated prices from Contracts/Orders\n   - Billing schedule for billing-triggered POBs\n\n2. **Apply POB Rules per Charge:**\n\n   **Over Time (Ratable):**\n   - Daily rate = Allocated Price ÷ Total Days\n   - Monthly amount = Daily rate × Days in month\n   - Example: $12,000 over 365 days = $32.88/day\n\n   **Point In Time:**\n   - 100% recognized in single period\n   - Period determined by POB (start date, completion event, etc.)\n\n   **Event-Driven:**\n   - Recognition triggered by events (usage, milestones)\n   - Amount based on event data\n   - $0 if no event data provided\n\n3. **Output Structure:**\n```json\n{\n  \"waterfall\": [\n    {\n      \"period\": \"2025-01\",\n      \"charges\": [\n        {\"name\": \"Platform\", \"amount\": 1019.18},\n        {\"name\": \"Setup Fee\", \"amount\": 5000.00}\n      ],\n      \"total\": 6019.18\n    }\n  ],\n  \"summary\": {\n    \"total_recognized\": 17000.00,\n    \"total_deferred\": 0.00\n  }\n}\n```\n\n**Critical Considerations:**\n- Event-driven POBs with no event data show $0 and flag an open question\n- Billing-gated POBs show $0 until billing occurs\n- SSP allocations affect amounts, not timing", "category": "conceptual", "topic": "Revenue waterfall generation"}
{"instruction": "How do I export training data from ZUCA?", "response": "ZUCA's self-learning system captures training data that can be exported for fine-tuning smaller models.\n\n**Training Data Sources:**\n\n1. **Evaluation Passes:**\n   - Outputs that pass evaluation criteria\n   - Captured with `--capture-training` flag\n\n2. **Correction Fixes:**\n   - Corrections with example fixes\n   - Synced via `training sync` command\n\n**Export Commands:**\n\n```bash\n# View statistics\nnpm run cli training stats\n\n# Sync corrections to training data\nnpm run cli training sync\n\n# List training examples\nnpm run cli training list --step billings --limit 20\n\n# Export to JSONL (OpenAI/HuggingFace format)\nnpm run cli training export data/zuora-training.jsonl\n\n# Export in HuggingFace format\nnpm run cli training export data/training.jsonl --format huggingface\n\n# Export balanced dataset\nnpm run cli training export data/balanced.jsonl --max-per-step 100\n\n# Filter by source\nnpm run cli training export data/passes.jsonl --source evaluation_pass\n```\n\n**Output Format (JSONL):**\n```json\n{\"messages\": [\n  {\"role\": \"system\", \"content\": \"[Step prompt]\"},\n  {\"role\": \"user\", \"content\": \"[Pipeline input]\"},\n  {\"role\": \"assistant\", \"content\": \"[Correct output]\"}\n]}\n```\n\n**Compatible With:**\n- HuggingFace TRL/SFTTrainer\n- Unsloth\n- OpenAI fine-tuning API\n- Any JSONL-compatible training pipeline\n\nTraining data is stored in `data/training-data.json`.", "category": "procedural", "topic": "Training data export"}
{"instruction": "What is the ZUCA Use Case Generator?", "response": "The Use Case Generator creates realistic Zuora use cases by researching a company's website and business model.\n\n**How It Works:**\n\n1. **Research Phase:**\n   - Fetches and analyzes the company website\n   - Identifies products, pricing models, customer segments\n   - Extracts business context\n\n2. **Generation Phase:**\n   - Creates realistic use case descriptions\n   - Infers billing models from pricing pages\n   - Generates complete ZucaInput structures\n\n3. **Fun Facts (Optional):**\n   - Adds company trivia for engagement\n   - Makes generated use cases more memorable\n\n**CLI Usage:**\n```bash\n# Generate 3 use cases for Salesforce\nnpm run cli -- generate \"Salesforce\" -w \"https://www.salesforce.com\" -c 3\n\n# With specific model and output file\nnpm run cli -- generate \"Twilio\" -w \"https://www.twilio.com\" -c 2 -m gemini-3-pro-preview -o generated/twilio.json\n\n# Interactive guided mode\nnpm run cli generate-interactive\nnpm run cli gi  # shorthand\n```\n\n**Options:**\n- `-w, --website <url>`: Company website (required)\n- `-c, --count <n>`: Number of use cases (1-3)\n- `-n, --notes <text>`: Additional guidance\n- `-o, --output <file>`: Save to JSON file\n- `-l, --local`: Local formatting (no LLM)\n- `-m, --model <model>`: LLM model\n\n**Use Cases for the Generator:**\n- Create test suites from real companies\n- Demo preparation with relevant examples\n- Training data generation\n- Competitive analysis", "category": "definitional", "topic": "Use Case Generator"}
{"instruction": "How does ZUCA handle multi-turn conversations?", "response": "ZUCA supports multi-turn conversations for follow-up questions and solution refinements.\n\n**How It Works:**\n\n1. **Session Tracking:**\n   - Each analysis creates a session with unique ID\n   - Sessions persist in Postgres (web) or memory (CLI)\n   - Contains full pipeline result and conversation history\n\n2. **Follow-Up Processing:**\n   - User asks follow-up question\n   - System has access to previous result context\n   - LLM generates response considering prior output\n\n3. **Response Types:**\n   ```json\n   {\n     \"type\": \"clarification|modification|information\",\n     \"content\": \"Response text\",\n     \"suggestedEdits\": [\n       {\n         \"path\": \"subscription_spec.rate_plans[0].charges[0].sellPrice\",\n         \"newValue\": 1500.00,\n         \"reason\": \"User requested price increase\"\n       }\n     ]\n   }\n   ```\n\n**Session Structure:**\n```typescript\ninterface PipelineSession {\n  id: string;\n  createdAt: Date;\n  lastUpdatedAt: Date;\n  input: ZucaInput;\n  result: Partial<ZucaOutput>;\n  model: LlmModel;\n  conversationHistory: Array<{\n    role: 'user' | 'assistant';\n    content: string;\n    timestamp: Date;\n  }>;\n}\n```\n\n**Example Flow:**\n1. User: \"Analyze annual SaaS at $1200/year\"\n2. ZUCA: Generates complete solution\n3. User: \"What if we add a setup fee of $500?\"\n4. ZUCA: Suggests modification, updates tables\n5. User: \"Make the billing quarterly instead\"\n6. ZUCA: Regenerates affected outputs\n\nSmart reruns only recalculate affected steps based on field dependencies.", "category": "conceptual", "topic": "Multi-turn conversations"}
{"instruction": "What is the ZUCA Revenue Snapshot feature?", "response": "Revenue Snapshot is a web-only feature that connects to live Zuora tenants to preview Revenue ingestion from Billing data.\n\n**Purpose:**\n- Preview what Zuora Revenue would see from Billing transactions\n- Visualize revenue recognition before actual ingestion\n- Identify potential issues early\n\n**Features:**\n\n1. **Live Tenant Connection:**\n   - Connects to Zuora Billing API\n   - Retrieves transactions and subscription data\n   - Credentials encrypted with `ZUORA_CREDENTIALS_KEY`\n\n2. **OTR Detection:**\n   - Identifies Over Time Recognition (OTR) eligible transactions\n   - Maps charges to POB templates\n\n3. **Waterfall Preview:**\n   - Generates monthly revenue recognition schedule\n   - Based on actual tenant data\n\n4. **Export Capabilities:**\n   - Excel export of waterfall data\n   - Pivot table views\n   - Column filtering\n\n5. **Visualization:**\n   - Rev Rec chart toggle\n   - Period-by-period breakdown\n   - Summary statistics\n\n**Pipeline Steps:**\n1. Build Waterfall - SSP allocations + periodization\n2. Summary - Consolidate assumptions and questions\n\n**Key Files:**\n- `src/pipeline/revenue-snapshot/` - Pipeline steps\n- `apps/web/lib/zuora.ts` - Data retrieval + OTR detection\n- `apps/web/components/revenue-snapshot-view.tsx` - UI/export\n\nRevenue Snapshot is separate from the main use case analysis pipeline.", "category": "definitional", "topic": "Revenue Snapshot feature"}
{"instruction": "How do I add new evaluation criteria to ZUCA?", "response": "Adding new evaluation criteria teaches ZUCA's judge to check for additional behavioral rules.\n\n**Step 1: Create or Edit Criteria File**\n\nLocation: `data/evaluation-criteria/<step-name>.yaml`\n\n```yaml\nname: billings-criteria\nversion: \"1.0\"\nstep: billings\ndescription: Rules for billing schedule generation\n\ncriteria:\n  - id: BL-NEW\n    name: your-rule-name\n    description: What this rule checks\n    severity: critical  # critical, high, medium, low\n    patterns:\n      - keyword1\n      - keyword2\n    check:\n      type: behavioral\n      rule: |\n        Detailed description of what constitutes correct behavior.\n        Be specific about edge cases.\n        Include numeric thresholds if applicable.\n    examples:\n      passing:\n        - scenario: \"Description of passing case\"\n          expected: \"What correct output looks like\"\n      failing:\n        - scenario: \"Description of failing case\"\n          incorrect: \"What wrong output looks like\"\n          why: \"Explanation of why this fails\"\n```\n\n**Step 2: Test the Criteria**\n\n```bash\n# Run evaluation to see if new criteria is applied\nnpm run cli evaluate --step billings\n\n# Check if criteria catches known bad outputs\nnpm run cli evaluate --suite test-suite --corrections\n```\n\n**Best Practices:**\n\n1. **Specific IDs:** Use step prefix (BL-, DS-, CO-, etc.)\n2. **Clear Rules:** Write rules as if explaining to a new team member\n3. **Real Examples:** Use actual passing/failing scenarios\n4. **Appropriate Severity:** Critical = breaks functionality, Low = style issue\n5. **Keyword Patterns:** Help the judge know when the rule applies\n\n**Criteria Files by Step:**\n- `design_subscription.yaml`\n- `billings.yaml`\n- `contracts_orders.yaml`\n- `revrec_waterfall.yaml`", "category": "procedural", "topic": "Adding evaluation criteria"}
{"instruction": "What is the difference between ZUCA pipeline v1 and v2?", "response": "ZUCA v2 introduced significant optimizations over v1:\n\n**Pipeline v1 (Legacy):**\n```\n1. Route Query\n2. Extract Contract Intel\n3. Detect Capabilities\n4. Match Golden Use Cases\n5. Generate Subscription Spec\n6. Assign POB Templates\n7. Build Contracts/Orders\n8. Build Billings\n9. Build Rev Rec Waterfall\n10. Summarize\n```\n- 10 sequential steps\n- 8 LLM calls\n- Higher latency\n\n**Pipeline v2 (Current):**\n```\n1. Analyze Contract (COMBINED)\n   - Contract Intel + Detect Capabilities\n2. Match Golden Use Cases (PURE CODE)\n3. Design Subscription (COMBINED)\n   - Subscription Spec + POB Templates\n4. Build Contracts/Orders + Billings (PARALLEL)\n5. Build Rev Rec Waterfall\n6. Summarize\n```\n- 6 logical steps\n- 5 LLM calls (2 combined, 2 parallel, 1 waterfall, 1 summary)\n- ~40% faster\n\n**Key Optimizations:**\n\n1. **Combined Steps:**\n   - Contract analysis + capability detection in one call\n   - Subscription design + POB mapping in one call\n   - Reduces context switching overhead\n\n2. **Parallel Execution:**\n   - Contracts/Orders and Billings run simultaneously\n   - No dependency between these outputs\n\n3. **Pure Code Matching:**\n   - Golden Use Case matching is algorithmic\n   - No LLM call needed for Jaccard similarity\n\n**Legacy Steps Still Available:**\nIndividual step functions exist for backwards compatibility and debugging, but the orchestrator uses combined/parallel execution by default.", "category": "conceptual", "topic": "Pipeline v1 vs v2"}
{"instruction": "How do I debug ZUCA pipeline issues?", "response": "ZUCA provides several debugging tools and techniques:\n\n**1. Enable Debug Logging:**\n```env\nDEBUG=true\n```\nShows detailed output including:\n- LLM requests and responses\n- Tool calls (web_search, code_interpreter)\n- Step timing and token usage\n- RAG retrieval results\n\n**2. Run Individual Steps:**\n```bash\n# Evaluate only one step\nnpm run cli evaluate --step billings\n\n# Quick capability detection only\nnpm run cli quick \"Your use case description\"\n```\n\n**3. Check Corrections:**\n```bash\n# See what mistakes have been recorded\nnpm run cli corrections list --step billings\n\n# View correction details\nnpm run cli corrections summary\n```\n\n**4. Review Evaluation Failures:**\n```bash\n# Run evaluation with corrections capture\nnpm run cli evaluate --suite golden-scenarios --corrections\n\n# Analyze failure patterns\nnpm run cli prompts analyze\n```\n\n**5. Test RAG Retrieval:**\n```bash\nnpm run rag:test \"your query\"\n```\n\n**6. Web App Debugging:**\n- Check browser console for API errors\n- Session data visible in database\n- API routes log to server console\n\n**Common Issues:**\n\n| Symptom | Likely Cause | Fix |\n|---------|--------------|-----|\n| Slow response | Large context | Check RAG chunk size |\n| Wrong POB | Missing criteria | Add evaluation rule |\n| Missing data | Prompt drift | Review prompt file |\n| Parse error | Schema mismatch | Sync Zod types with JSON schema |\n\n**Key Log Patterns:**\n- `[STEP]` - Pipeline step execution\n- `[LLM]` - LLM API calls\n- `[RAG]` - Document retrieval\n- `[MCP]` - Zuora API tool calls", "category": "procedural", "topic": "Debugging ZUCA"}
